# 简介
Celery 通过消息机制进行通信，通常使用中间人（Broker）作为客户端和职程（Worker）调节。
启动一个任务，客户端向消息队列发送一条消息，然后中间人（Broker）将消息传递给一个职程（Worker），最后由职程（Worker）进行执行中间人（Broker）分配的任务。

Celery 可以有多个职程（Worker）和中间人（Broker），用来提高Celery的高可用性以及横向扩展能力。

![](./images/celery_flow.png)


Celery的架构由三部分组成，消息中间件（message broker），任务执行单元（worker）和任务执行结果存储（task result store）组成
- 消息(队列)中间件: Celery本身不提供消息服务，但是可以方便的和第三方提供的消息中间件集成. 支持 RabbitMQ, Redis等等
- 任务执行单元: Worker是Celery提供的任务执行的单元，worker并发的运行在分布式的系统节点中
- 任务结果存储: 用来存储Worker执行的任务的结果

tip: 本教程以redis作为broker的消息队列中间件以及任务执行结果存储
## 资料
1. https://docs.celeryproject.org 官方文档
2. https://www.cnblogs.com/rossiXYZ/category/1932086.html 源码分析
3. https://flower.readthedocs.io/en/latest/  flower用于对celery的task进行监控,但此监控不支持celery5.x
4. https://pythondjango.cn/django/advanced/12-sync-periodic-tasks-with-celery 使用博客

## 安装
- `pip install celery`: 安装celery
- `pip install django-celery-beat`: 安装定时任务(django版)
- `pip install redis`: 如果需要用到redis需要安装

## 使用

### 工程结构
```py
- myproject/
  - manage.py
  - project/
    - __init__.py  # 修改这个文件
    - celery.py  # 新增这个文件
    - asgi.py
    - settings.py
    - urls.py
    - wsgi.py
```
1. 在工程子应用文件夹新建`celery.py`文件,用于实例化celery
2. 在工程子应用`__init__.py`中注册实例
3. 在`setting.py`文件中声明配置

### 命令
celery命令
```py
Options

-A, --app <app>
-b, --broker <broker>
--result-backend <result_backend>
--loader <loader>
--config <config>
--workdir <workdir>
-C, --no-color
-q, --quiet
--version
```
`celery multi start w1 -A demo -l info --pidfile=./celery/%n.pid --logfile=./celery/%n%I.log`: 设置后台运行


celery beat 命令
```py
Options

--detach: 后台运行
--max-interval <max_interval> 间隔数
-l, --loglevel <loglevel>: 日志
    Options
    DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL

-f, --logfile <logfile>
--pidfile <pidfile>
```
`celery -A demo beat -l info --detach`: 设置后台运行
### 配置
`celery.py`
```py
import os
from celery import Celery

# 设置环境变量
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')

# 实例化
app = Celery('myproject')  # celery实例名为`myproject`,如果不设置则默认为工程名

# namespace='CELERY'作用是允许你在Django配置文件中对Celery进行配置
# 但所有Celery配置项必须以CELERY开头，防止冲突
app.config_from_object('django.conf:settings', namespace='CELERY')

# 自动从Django的已注册app中发现任务
app.autodiscover_tasks()  # 默认从每个应用文件夹中`tasks.py`查找任务. 如果直接传入 列表/元组 则去指定地方

# 一个测试任务
@app.task(bind=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
```

`__init__.py`
```py
from __future__ import absolute_import, unicode_literals  # 声明绝对路径
from pymysql import install_as_MySQLdb
from .celery import app as celery_app


install_as_MySQLdb()
__all__ = ('celery_app',)  # 注册
```

`setting.py`
```py
# 需要以CELERY开头

CELERY_BROKER_URL = 'redis://127.0.0.1:32768/0'
CELERY_RESULT_BACKEND = 'redis://127.0.0.1:32768/1'

CELERY_TIMEZONE = TIME_ZONE
CELERY_ENABLE_UTC = False


CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'

CELERY_TASK_TIME_LIMIT = 10
CELERY_RESULT_EXPIRES = 60 * 60

# CELERY_TASK_ANNOTATIONS = {'tasks.add': {'rate_limit': '10/s'}}  # 任务限流

CELERY_WORKER_MAX_TASKS_PER_CHILD = 100

# CELERY_IGNORE_RESULT = True

CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'

DJANGO_CELERY_BEAT_TZ_AWARE = False
```
- CELERY_BROKER_URL: 消息队列地址
- CELERY_RESULT_BACKEND: 任务结果后端设置
- CELERY_TIMEZONE: 时区,默认为UTC
- CELERY_ENABLE_UTC: 转换为使用 UTC 时区, 默认为True
- CELERY_ACCEPT_CONTENT: 允许的内容类型, 默认为 {'json'}
- CELERY_TASK_SERIALIZER: 序列化字符串,默认为 json
- CELERY_RESULT_SERIALIZER:  序列化字符串,默认为 json
- CELERY_TASK_TIME_LIMIT: 硬性运行时间,若超时就杀死
- CELERY_TASK_SOFT_TIME_LIMIT: 软性运行时间,若超时就报错,抛出`celery.exceptions.SoftTimeLimitExceeded`错误
- CELERY_RESULT_EXPIRES: 结果过期删除时间
- CELERY_IGNORE_RESULT:　是否存储任务返回值，默认为False
- CELERY_BEAT_SCHEDULER: 定时器调度程序
- CELERY_WORKER_CONCURRENCY  Worker并发数量，一般默认CPU核数，可以不设置
- CELERY_WORKER_MAX_TASKS_PER_CHILD  每个worker执行了多少任务就会死掉，默认是无限的
- CELERY_TASK_ANNOTATIONS  任务限流, 可以用 `*` 代表全部task
- DJANGO_CELERY_BEAT_TZ_AWARE: beat的时区是否为UTC

#### 校验
`celery -A myproject worker -l info`
- myproject为实例化时传入的名字,默认为项目名

运行celery,校验上述配置是否成功可用
### 任务

- shared_tash: 创建任务的独立实例，使任务可重用

`tasks.py`
```py
import time
from celery import shared_task


@shared_task
def add(x, y):
    time.sleep(2)
    return x + y
```

### 调用
方法一：delay方法
- task_name.delay(args1, args2, kwargs=value_1, kwargs2=value_2)

方法二： apply_async方法，与delay类似，但支持更多参数
- task.apply_async(args=[arg1, arg2], kwargs={key:value, key:value})
```py
a = add.delay(3, 5)  # <AsyncResult: 12095894-956f-4933-b880-afaae9782e44>
a.ready()  # 状态
a.result  # 结果
a.get()  # 结果
```
### 查看结果
通过`celery.result.AsyncResult`类,传入任务id可以得到 Result实例.
- .status: 状态
- .result: 结果
- .id: 任务唯一序列号
```py
from celery.result import AsyncResult
# 调用异步任务
async_task = add.apply_async(args=[3, 5])
# 获取任务状态和结果
AsyncResult(async_task.task_id).status
AsyncResult(async_task.task_id).result
```
### 定时任务
定时任务celery 支持两种,一种是直接写死的定时任务,一种是支持自定义增删的定时任务

写死的定时任务,本文略过.只将自定义的定时任务

`CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'` 通过修改调度器,实现基于数据库存储定时任务

#### 安装
`pip install django-celery-beat`

#### 注册
在`setting.py`中注册
```py
INSTALLED_APPS = [
    # ...
    'django_celery_beat',
]
```

#### migrate
因为需要创建数据库表所以要进行迁移

`python manage.py migrate`


如果设置了数据库路由,需要指定数据库,否则将访问默认数据库
```py
DATABASE_APPS_MAPPING = {
    # ....
    'django_celery_beat': 'mysql'
}
```
#### 模型
`django_celery_beat.models`中

提供了四种定时方式
- SolarSchedule: 通过经纬度的天文状态来定时
- ClockedSchedule: 时间
- IntervalSchedule: 间隔
- CrontabSchedule: cron模式(常用)


提供了任务表
- PeriodicTasks: 此模型仅用作跟踪时间表何时更改的索引(可忽略)
- PeriodicTask: 存储task的表


本文仅详细讲解CrontabSchedule定时方式,该定时方式都具有默认值
- minute, 默认*
- hour, 默认*
- day_of_week, 默认*
- day_of_month, 默认*
- month_of_year, 默认*
- timezone, 默认为配置时区

格式: 
- 9: 数字
- `[1-5]`: 列表
- {1, 2, 3, 5}: 集合
- '3-5': 字符串
- '*/2': 字符串

PeriodicTask
- name: 名字
- task: 任务地址 (格式:子应用.文件夹.方法)
- interval: 间隔策略外键, 四选一
- crontab: cron策略外键, 四选一
- solar: solar策略外键, 四选一
- clocked: clocked策略外键, 四选一
- args: 位置参数, 参数需要转化为json
- kwargs: 关键字参数, 参数需要转化为json
- queue: 队列
- exchange: 用于AMQP (忽略)
- routing_key: 用于AMQP (忽略)
- headers: 用于AMQP的头信息 (忽略)
- priority: 优先级 0-255. 0为最高
- expires: 过期时间 (DateTime)
- expire_seconds: 过期时间(秒)
- one_off: 是否仅运行一次
- start_time: 生效时间
- enabled: 开关
- last_run_at: 上次运行时间,自动更新
- total_run_count: 运行总次数,自动更新
- date_changed: 更新时间,自动更新
- description: 详情

tip: 传入的参数务必为json格式,否则运行时会报错.报错时会在periodictask表生成新的数据,需要进行清理才能继续运行
#### 添加定时任务
一般来说`PeriodicTask`模型仅需传入`name`,`task`,`策略`,`参数`即可
```py
import json
from django_celery_beat.schedulers import CrontabSchedule, PeriodicTask

schedule = CrontabSchedule.objects.create(minute="*/2")

PeriodicTask.objects.create(name="beat_task", task="app.tasks.add", crontab=schedule, args=json.dumps((3, 5)))
```
#### 注意事项
1. 如果更改了时区,需要对定时任务进行修改
```py
from django_celery_beat.models import PeriodicTask, PeriodicTasks

PeriodicTask.objects.all().update(last_run_at=None)  # 将上次运行时间置空
for task in PeriodicTask.objects.all():  # 遍历全部任务
    PeriodicTasks.changed(task)  # 修改时区
```

2. 如果批量更新定时任务
```py
from django_celery_beat.models import PeriodicTasks


PeriodicTasks.update_changed()
```

### 重试
定义任务时可以通过max_retries设置最大重试次数，并调用`self.retry`方法调用。因为要调用`self`这个参数，定义任务时必须设置`bind=True`。

在装饰器中加入参数 bind=True
- 在task函数中的第一个参数设置为self
- self对象是celery.app.task.Task的实例，可以用于实现重试等多种功能
```py
@shared_task(bind=True, max_retries=3)
def send_batch_notifications(self):
   try:
       something_raising()
       raise Exception('Can\'t doing.')
   except Exception as exc:
       self.retry(exc=exc, countdown=5)
   send_mail(
       subject='Batch email notifications',
       message='Test email',
       from_email='no-reply@example.com',
       recipient_list=['john@example.com']
   )
```
## 信号
https://docs.celeryproject.org/en/latest/userguide/signals.html

`celery.signals`提供了多种信号, 可以利用信号机制实现另外的自定义操作

以下是task任务监控的实现
```py
import logging
from django.utils.timezone import now
from django.db import OperationalError, InterfaceError
from django.db import close_old_connections
from celery.signals import task_failure, task_postrun, task_received, task_revoked
from api.models import TaskExecute
from api.tasks import run


@task_received.connect()
def task_received_handler(request, **kwargs):
    if request.name == "api.tasks.run":
        logging.debug(f"Received Task. id:{request.task_id} worker:{request.hostname}")
        try:
            instance, _ = TaskExecute.objects.get_or_create(uuid=request.task_id)
        except (OperationalError, InterfaceError) as e:
            logging.error(f"Lost connection! Task_id: {request.task_id} Traceback: {e}")
            close_old_connections()  # 因为他是由worker执行的 如果网络不好可能会丢失, 使用这个重连
            instance, _ = TaskExecute.objects.get_or_create(uuid=request.task_id)
        instance.worker = request.hostname
        instance.received = now()
        instance.state = "RECEIVED"
        instance.save()


@task_postrun.connect(sender=run)
def task_postrun_handler(task_id, retval, state, **kwargs):
    logging.debug(f"Postrun Task. id:{task_id} state:{state} retval:{retval}")
    instance, _ = TaskExecute.objects.get_or_create(uuid=task_id)
    instance.finished = now()
    if state:
        instance.done = True
        instance.state = state
    if retval:
        instance.result = str(retval)
    instance.save()


@task_failure.connect(sender=run)
def task_failure_handler(task_id, einfo, **kwargs):
    logging.debug(f"Failure Task. id:{task_id} traceback:{einfo.traceback}")
    instance, _ = TaskExecute.objects.get_or_create(uuid=task_id)
    instance.traceback = einfo.traceback
    instance.save()


@task_revoked.connect(sender=run)
def task_revoked_handler(request, **kwargs):
    logging.debug(f"Revoked Task. id:{request.id}")
    instance, _ = TaskExecute.objects.get_or_create(uuid=request.id)
    if instance.state != "TERMINATED":
        instance.state = "TERMINATED"
        instance.done = True
        instance.save()

```

## 命令
### celery命令
```py
Options

-A, --app <app>
-b, --broker <broker>
--result-backend <result_backend>
--loader <loader>
--config <config>
--workdir <workdir>
-C, --no-color
-q, --quiet
--version
```
`celery multi start w1 -A demo -l info --pidfile=./celery/%n.pid --logfile=./celery/%n%I.log`: 设置后台运行
- w1: 名字,可以为任意
- `%n`: 名字占位符
- `%I`: 进程序号

inspect
- `celery -A 工程 inspect stats`: 查看状态
- `celery -A 工程 inspect active`: 查看活跃
- `celery -A 工程 inspect registerd`: 注册任务

其他
- `celery -A 工程 control enable_events`: 如果出现任务监控无数据,则需要打开事件
- `celery -A 工程 events`: 任务监控

- `celery -A 工程 -c 200`: worker 数量

后台运行
- `celery multi kill` 名字 -A 工程
- `celery multi stopwait` 名字 -A 工程
- `celery multi stop` 名字 -A 工程
- `celery multi restart` 名字 -A 工程
- `celery multi start` 名字 -A 工程
### celery beat 命令
```py
Options

--detach: 后台运行
--max-interval <max_interval> 间隔数
-l, --loglevel <loglevel>: 日志
    Options
    DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL

-f, --logfile <logfile>
--pidfile <pidfile>
```
- `celery -A 工程名 beat -l info`: 运行beat
- `celery -A 工程名 beat -l info --detach`: 设置后台运行

## 监控
https://lxkaka.wang/celery-monitor/

### 自定义监控
## 调试