https://docs.celeryproject.org 官方文档

https://www.celerycn.io

https://flower.readthedocs.io/en/latest/  此监控不支持celery5.x

https://pythondjango.cn/django/advanced/12-sync-periodic-tasks-with-celery

本文主要是与django结合使用:

配置:

celery.py
```py
from __future__ import absolute_import, unicode_literals  # 用于访问绝对路径
import os
from celery import Celery


os.environ.setdefault("DJANGO_SETTINGS_MODULE", 'demo.settings')  # 设置环境变量

app = Celery()

app.config_from_object('django.conf:settings', namespace="CELERY")  # 声明配置文件, namespace的意思是配置文件的前缀为 CELERY

app.autodiscover_tasks()  # 自动发现, 也可以传入task文件地址 ["task.task"]


@app.task(bind=True)  # 测试用task
def debug_task(self):
    print(self.request, "==============================")
```

setting.py 也可以独立放在一个文件内
```py
CELERY_BROKER_URL = 'redis://127.0.0.1:32768/0'
CELERY_RESULT_BACKEND = 'redis://127.0.0.1:32768/1'

CELERY_TIMEZONE = TIME_ZONE
CELERY_ENABLE_UTC = False
DJANGO_CELERY_BEAT_TZ_AWARE = False

CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'

CELERY_TASK_TIME_LIMIT = 10
CELERY_RESULT_EXPIRES = 60 * 60

# CELERY_TASK_ANNOTATIONS = {'tasks.add': {'rate_limit': '10/s'}}  # 限流

CELERY_WORKER_MAX_TASKS_PER_CHILD = 100

# CELERY_IGNORE_RESULT = True  # 不保存结果

CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'
```
init.py
```py
from __future__ import absolute_import, unicode_literals
from .celery import app as celery_app


install_as_MySQLdb()
__all__ = ('celery_app',)
```

tasks.py 放在每个应用中,文件名不可变!也可以统一放在一个文件夹中,此时需要在`autodiscover_tasks`中声明地址

```py
import time
from celery import shared_task


@shared_task
def add(x, y):
    time.sleep(2)
    return x + y


@shared_task
def reduce(x, y):
    time.sleep(2)
    return x - y
```

信号
```py
from celery.signals import task_failure, task_postrun, task_prerun, task_success, task_received


@receiver(task_prerun)
def task_prerun_handler(task_id, task, *args, **kwargs):
    print("===========task_prerun_handler============")
    print("name:", task.name, "id:", task_id)
    print(args)
    print(kwargs)
    print("sender:", kwargs.get("sender").__dict__)


@receiver(task_success)
def task_success_handler(sender, result, **kwargs):
    print("===========task_success_handler==============")
    print("sender:", sender.name)
    # print("task_done", sender.date_done)
    print(result)
    print(kwargs)
    print(sender)
    print(sender.__class__)


@receiver(task_postrun)
def task_postrun_handler(task_id, task, *args, **kwargs):
    print("===========task_postrun_handler============")
    print(task)
    print("name:", task.name, "id:", task_id)
    print("stats", kwargs.get("state"))
    print(args)
    print(kwargs)
    print("sender:", kwargs.get("sender").__dict__)
    print("retval:", kwargs.get("retval"))
```
调用task
```py
# 方法一：delay方法
task_name.delay(args1, args2, kwargs=value_1, kwargs2=value_2)

# 方法二： apply_async方法，与delay类似，但支持更多参数
task.apply_async(args=[arg1, arg2], kwargs={key:value, key:value})
```
运行命令:

```
celery -A demo beat -l info  开启beat


celery -A 程序名 worker -l info


celery multi start w1 -A demo -l info --pidfile=./celery/%n.pid --logfile=./celery/%n%I.log
开启后台运行w1任务 程序为demo 输出pid和log文件

celery -A demo events 查看事件
```

定时器
pip django-celery-beat

installed_app中注册`django-celery-beat`

如果设置了数据库路由,需要指定数据库,否则将访问默认数据库
'django_celery_beat': 'mysql'

重试次数

数据库添加定时任务
```py
from django_celery_beat.models import PeriodicTask, CrontabSchedule


```